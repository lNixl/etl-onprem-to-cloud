version: "3.9"

services:
  # ============ SPARK ============
  spark-master:
    image: apache/spark:3.5.7-scala2.12-java17-python3-r-ubuntu
    container_name: spark-master
    command: >
      bash -c "/opt/spark/sbin/start-master.sh && tail -f /dev/null"
    ports:
      - "8081:8080"   # Spark UI
      - "7077:7077"   # Cluster port
    environment:
      - SPARK_MODE=master
    volumes:
      - ./etl:/opt/etl
      - ./data:/opt/data

  spark-worker:
    image: apache/spark:3.5.7-scala2.12-java17-python3-r-ubuntu
    container_name: spark-worker
    command: >
      bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
    volumes:
      - ./etl:/opt/etl
      - ./data:/opt/data

  # ============ AIRFLOW BACKEND ============
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:latest
    ports:
      - "6379:6379"

  # ============ AIRFLOW INIT ============
  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    env_file:
      - .env
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: "rS0qGh5hXIoCAel-oWblxGUEgosa-W2mmFaydfJ9Vv8="
    command: >
      bash -c "airflow db init &&
               airflow users create
                 --username admin
                 --password admin
                 --firstname admin
                 --lastname admin
                 --role Admin
                 --email admin@example.com
               || true"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./etl:/opt/etl
      - ./data:/opt/data

  # ============ AIRFLOW WEB ============
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    env_file:
      - .env
    depends_on:
      - airflow-init
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: "rS0qGh5hXIoCAel-oWblxGUEgosa-W2mmFaydfJ9Vv8="
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    ports:
      - "8080:8080"
    command: webserver
    volumes:
      - ./dags:/opt/airflow/dags
      - ./etl:/opt/etl
      - ./data:/opt/data

  # ============ AIRFLOW SCHEDULER ============
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    env_file:
      - .env
    depends_on:
      - airflow-init
      - airflow-webserver
      - redis
      - postgres
    command: scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: "rS0qGh5hXIoCAel-oWblxGUEgosa-W2mmFaydfJ9Vv8="
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./etl:/opt/etl
      - ./data:/opt/data

volumes:
  postgres_data:
